{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2_keras_lenet_mnist.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dalgual/bigdai.github.io/blob/main/python/orca/colab-notebook/quickstart/tf2_keras_lenet_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgV_QLGE9Lox"
      },
      "source": [
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDBPZ0_rfBmU"
      },
      "source": [
        "##### Copyright 2016 The BigDL Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBWVU_bhfkY7"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "#"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voMBntim9bMf"
      },
      "source": [
        "## **Environment Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccXnsv_pMCHQ"
      },
      "source": [
        "**Install Java 8**\n",
        "\n",
        "Run the cell on the **Google Colab** to install jdk 1.8.\n",
        "\n",
        "**Note:** if you run this notebook on your computer, root permission is required when running the cell to install Java 8. (You may ignore this cell if Java 8 has already been set up in your computer).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWx_0DSnXVhz",
        "outputId": "45d98c14-247d-4e5c-a3bc-3e5915fff823",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install jdk8\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "# Set environment variable JAVA_HOME.\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"1.8.0_312\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_312-8u312-b07-0ubuntu1~18.04-b07)\n",
            "OpenJDK 64-Bit Server VM (build 25.312-b07, mixed mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_OS4HKJMNpv"
      },
      "source": [
        "**Install BigDL Orca**\n",
        "\n",
        "You can install the latest pre-release version using `pip install --pre --upgrade bigdl-orca`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qfT8CaC51hI",
        "outputId": "2dfd5f0d-a9c3-45a0-8b19-c06216c08c2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install latest pre-release version of BigDL Orca \n",
        "# Installing BigDL Orca from pip will automatically install pyspark, bigdl, and their dependencies.\n",
        "!pip install --pre --upgrade bigdl-orca[ray]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bigdl-orca[ray]\n",
            "  Downloading bigdl_orca-2.1.0b202203171-py3-none-manylinux1_x86_64.whl (23.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.9 MB 63.6 MB/s \n",
            "\u001b[?25hCollecting conda-pack==0.3.1\n",
            "  Downloading conda_pack-0.3.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting bigdl-tf==0.14.0.dev1\n",
            "  Downloading bigdl_tf-0.14.0.dev1-py3-none-manylinux2010_x86_64.whl (71.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 71.0 MB 352 bytes/s \n",
            "\u001b[?25hCollecting bigdl-dllib==2.1.0b202203171\n",
            "  Downloading bigdl_dllib-2.1.0b202203171-py3-none-manylinux1_x86_64.whl (107.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 107.0 MB 21 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from bigdl-orca[ray]) (22.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from bigdl-orca[ray]) (3.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bigdl-orca[ray]) (21.3)\n",
            "Collecting bigdl-math==0.14.0.dev1\n",
            "  Downloading bigdl_math-0.14.0.dev1-py3-none-manylinux2010_x86_64.whl (35.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 35.4 MB 406 kB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from bigdl-orca[ray]) (5.4.8)\n",
            "Collecting async-timeout==4.0.1\n",
            "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
            "Collecting aiohttp==3.8.1\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 42.7 MB/s \n",
            "\u001b[?25hCollecting ray[default]==1.9.2\n",
            "  Downloading ray-1.9.2-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 57.6 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting hiredis==2.0.0\n",
            "  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting aioredis==1.3.1\n",
            "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (36 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca[ray]) (21.4.0)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 44.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca[ray]) (2.0.12)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 44.3 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca[ray]) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from bigdl-dllib==2.1.0b202203171->bigdl-orca[ray]) (1.15.0)\n",
            "Collecting pyspark==2.4.6\n",
            "  Downloading pyspark-2.4.6.tar.gz (218.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 218.4 MB 53 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from bigdl-dllib==2.1.0b202203171->bigdl-orca[ray]) (1.21.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from conda-pack==0.3.1->bigdl-orca[ray]) (57.4.0)\n",
            "Collecting py4j==0.10.7\n",
            "  Downloading py4j-0.10.7-py2.py3-none-any.whl (197 kB)\n",
            "\u001b[K     |████████████████████████████████| 197 kB 41.2 MB/s \n",
            "\u001b[?25hCollecting redis>=3.5.0\n",
            "  Downloading redis-4.2.0rc3-py3-none-any.whl (224 kB)\n",
            "\u001b[K     |████████████████████████████████| 224 kB 35.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca[ray]) (4.3.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca[ray]) (3.13)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca[ray]) (7.1.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca[ray]) (1.0.3)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca[ray]) (1.44.0)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca[ray]) (3.17.3)\n",
            "Collecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.4.0.dev1-py2.py3-none-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 35.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca[ray]) (0.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca[ray]) (2.23.0)\n",
            "Collecting gpustat>=1.0.0b1\n",
            "  Downloading gpustat-1.0.0b1.tar.gz (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 170 kB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca[ray]) (5.2.1)\n",
            "Collecting opencensus\n",
            "  Downloading opencensus-0.8.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 57.2 MB/s \n",
            "\u001b[?25hCollecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting colorful\n",
            "  Downloading colorful-0.6.0a1-py2.py3-none-any.whl (202 kB)\n",
            "\u001b[K     |████████████████████████████████| 202 kB 37.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]==1.9.2->bigdl-orca[ray]) (7.352.0)\n",
            "Collecting blessed>=1.17.1\n",
            "  Downloading blessed-1.19.1-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.7/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0b1->ray[default]==1.9.2->bigdl-orca[ray]) (0.2.5)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.2.0rc2-py3-none-any.whl (223 kB)\n",
            "\u001b[K     |████████████████████████████████| 223 kB 48.5 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.0rc1-py3-none-any.whl (220 kB)\n",
            "\u001b[K     |████████████████████████████████| 220 kB 53.7 MB/s \n",
            "\u001b[?25h  Downloading redis-4.1.4-py3-none-any.whl (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 42.1 MB/s \n",
            "\u001b[?25hCollecting deprecated>=1.2.3\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]==1.9.2->bigdl-orca[ray]) (4.11.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[default]==1.9.2->bigdl-orca[ray]) (1.13.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[default]==1.9.2->bigdl-orca[ray]) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bigdl-orca[ray]) (3.0.7)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.8.1->bigdl-orca[ray]) (2.10)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]==1.9.2->bigdl-orca[ray]) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]==1.9.2->bigdl-orca[ray]) (0.18.1)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]==1.9.2->bigdl-orca[ray]) (1.26.3)\n",
            "Collecting opencensus-context==0.1.2\n",
            "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca[ray]) (2018.9)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca[ray]) (1.35.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca[ray]) (1.55.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca[ray]) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca[ray]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca[ray]) (4.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca[ray]) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]==1.9.2->bigdl-orca[ray]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]==1.9.2->bigdl-orca[ray]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]==1.9.2->bigdl-orca[ray]) (2021.10.8)\n",
            "Building wheels for collected packages: pyspark, gpustat\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.6-py2.py3-none-any.whl size=218814407 sha256=7f2568a234accc4a1bd01a8eb52f3479076d2fc56f8057ff51669691a945a396\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/42/b0/ba397759613f4feb1611021a2503e60e344e546671b2ae04f8\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.0.0b1-py3-none-any.whl size=15979 sha256=547a8bb64627107938c4a9fdd1eed7e17ebac38ea775102998077aceb084c5c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/16/e2/3e2437fba4c4b6a97a97bd96fce5d14e66cff5c4966fb1cc8c\n",
            "Successfully built pyspark gpustat\n",
            "Installing collected packages: multidict, frozenlist, yarl, py4j, deprecated, asynctest, async-timeout, aiosignal, redis, pyspark, opencensus-context, hiredis, blessed, aiohttp, ray, py-spy, opencensus, gpustat, conda-pack, colorful, bigdl-tf, bigdl-math, bigdl-dllib, aioredis, aiohttp-cors, setproctitle, bigdl-orca\n",
            "Successfully installed aiohttp-3.8.1 aiohttp-cors-0.7.0 aioredis-1.3.1 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 bigdl-dllib-2.1.0b202203171 bigdl-math-0.14.0.dev1 bigdl-orca-2.1.0b202203171 bigdl-tf-0.14.0.dev1 blessed-1.19.1 colorful-0.6.0a1 conda-pack-0.3.1 deprecated-1.2.13 frozenlist-1.3.0 gpustat-1.0.0b1 hiredis-2.0.0 multidict-6.0.2 opencensus-0.8.0 opencensus-context-0.1.2 py-spy-0.4.0.dev1 py4j-0.10.7 pyspark-2.4.6 ray-1.9.2 redis-4.1.4 setproctitle-1.2.2 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-l4vel5N3qP"
      },
      "source": [
        "## **Distributed TensorFlow 2 using Orca APIs**\n",
        "\n",
        "In this guide we will describe how to scale out TensorFlow 2 programs using Orca in 4 simple steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDPt2XTsT-Gv"
      },
      "source": [
        "# import necesary libraries and modules\n",
        "import argparse\n",
        "\n",
        "from bigdl.orca import init_orca_context, stop_orca_context\n",
        "from bigdl.orca import OrcaContext"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBdeoZzLWWlY"
      },
      "source": [
        "### **Step 1: Init Orca Context** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAQp0FcUWaH3",
        "outputId": "fc531310-138c-47c3-a85d-13c8dd71e469",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# recommended to set it to True when running BigDL in Jupyter notebook \n",
        "OrcaContext.log_output = True # (this will display terminal's stdout and stderr in the Jupyter notebook).\n",
        "\n",
        "cluster_mode = \"local\"\n",
        "\n",
        "if cluster_mode == \"local\":  \n",
        "    init_orca_context(cluster_mode=\"local\", cores=1) # run in local mode\n",
        "elif cluster_mode == \"k8s\":  \n",
        "    init_orca_context(cluster_mode=\"k8s\", num_nodes=2, cores=2) # run on K8s cluster\n",
        "elif cluster_mode == \"yarn\":  \n",
        "    init_orca_context(cluster_mode=\"yarn-client\", num_nodes=2, cores=2) # run on Hadoop YARN cluster"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing orca context\n",
            "Current pyspark location is : /usr/local/lib/python3.7/dist-packages/pyspark/__init__.py\n",
            "Start to getOrCreate SparkContext\n",
            "pyspark_submit_args is:  --driver-class-path /usr/local/lib/python3.7/dist-packages/bigdl/share/orca/lib/bigdl-orca-spark_2.4.6-2.1.0-SNAPSHOT-jar-with-dependencies.jar:/usr/local/lib/python3.7/dist-packages/bigdl/share/dllib/lib/bigdl-dllib-spark_2.4.6-2.1.0-SNAPSHOT-jar-with-dependencies.jar pyspark-shell \n",
            "[main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-18 01:02:21,174 Thread-4 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n",
            "2022-03-18 01:02:21,182 Thread-4 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n",
            "2022-03-18 01:02:21,191 Thread-4 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n",
            "2022-03-18 01:02:21,193 Thread-4 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n",
            "22-03-18 01:02:21 [Thread-4] INFO  Engine$:121 - Auto detect executor number and executor cores number\n",
            "22-03-18 01:02:21 [Thread-4] INFO  Engine$:123 - Executor number is 1 and executor cores number is 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "User settings:\n",
            "\n",
            "   KMP_AFFINITY=granularity=fine,compact,1,0\n",
            "   KMP_BLOCKTIME=0\n",
            "   KMP_SETTINGS=1\n",
            "   OMP_NUM_THREADS=1\n",
            "\n",
            "Effective settings:\n",
            "\n",
            "   KMP_ABORT_DELAY=0\n",
            "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
            "   KMP_ALIGN_ALLOC=64\n",
            "   KMP_ALL_THREADPRIVATE=128\n",
            "   KMP_ATOMIC_MODE=2\n",
            "   KMP_BLOCKTIME=0\n",
            "   KMP_CPUINFO_FILE: value is not defined\n",
            "   KMP_DETERMINISTIC_REDUCTION=false\n",
            "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
            "   KMP_DISP_HAND_THREAD=false\n",
            "   KMP_DISP_NUM_BUFFERS=7\n",
            "   KMP_DUPLICATE_LIB_OK=false\n",
            "   KMP_FORCE_REDUCTION: value is not defined\n",
            "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
            "   KMP_FORKJOIN_BARRIER='2,2'\n",
            "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
            "   KMP_FORKJOIN_FRAMES=true\n",
            "   KMP_FORKJOIN_FRAMES_MODE=3\n",
            "   KMP_GTID_MODE=3\n",
            "   KMP_HANDLE_SIGNALS=false\n",
            "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
            "   KMP_HOT_TEAMS_MODE=0\n",
            "   KMP_INIT_AT_FORK=true\n",
            "   KMP_ITT_PREPARE_DELAY=0\n",
            "   KMP_LIBRARY=throughput\n",
            "   KMP_LOCK_KIND=queuing\n",
            "   KMP_MALLOC_POOL_INCR=1M\n",
            "   KMP_MWAIT_HINTS=0\n",
            "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
            "   KMP_PLAIN_BARRIER='2,2'\n",
            "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
            "   KMP_REDUCTION_BARRIER='1,1'\n",
            "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
            "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
            "   KMP_SETTINGS=true\n",
            "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
            "   KMP_STACKOFFSET=64\n",
            "   KMP_STACKPAD=0\n",
            "   KMP_STACKSIZE=8M\n",
            "   KMP_STORAGE_MAP=false\n",
            "   KMP_TASKING=2\n",
            "   KMP_TASKLOOP_MIN_TASKS=0\n",
            "   KMP_TASK_STEALING_CONSTRAINT=1\n",
            "   KMP_TEAMS_THREAD_LIMIT=2\n",
            "   KMP_TOPOLOGY_METHOD=all\n",
            "   KMP_USER_LEVEL_MWAIT=false\n",
            "   KMP_USE_YIELD=1\n",
            "   KMP_VERSION=false\n",
            "   KMP_WARNINGS=true\n",
            "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
            "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
            "   OMP_CANCELLATION=false\n",
            "   OMP_DEBUG=disabled\n",
            "   OMP_DEFAULT_DEVICE=0\n",
            "   OMP_DISPLAY_AFFINITY=false\n",
            "   OMP_DISPLAY_ENV=false\n",
            "   OMP_DYNAMIC=false\n",
            "   OMP_MAX_ACTIVE_LEVELS=2147483647\n",
            "   OMP_MAX_TASK_PRIORITY=0\n",
            "   OMP_NESTED=false\n",
            "   OMP_NUM_THREADS='1'\n",
            "   OMP_PLACES: value is not defined\n",
            "   OMP_PROC_BIND='intel'\n",
            "   OMP_SCHEDULE='static'\n",
            "   OMP_STACKSIZE=8M\n",
            "   OMP_TARGET_OFFLOAD=DEFAULT\n",
            "   OMP_THREAD_LIMIT=2147483647\n",
            "   OMP_TOOL=enabled\n",
            "   OMP_TOOL_LIBRARIES: value is not defined\n",
            "   OMP_WAIT_POLICY=PASSIVE\n",
            "   KMP_AFFINITY='noverbose,warnings,respect,granularity=fine,compact,1,0'\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22-03-18 01:02:23 [Thread-4] INFO  ThreadPool$:95 - Set mkl threads to 1 on thread 14\n",
            "[Thread-4] WARN  org.apache.spark.SparkContext  - Using an existing SparkContext; some configuration may not take effect.\n",
            "22-03-18 01:02:23 [Thread-4] INFO  Engine$:446 - Find existing spark context. Checking the spark conf...\n",
            "cls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.Sample\n",
            "BigDLBasePickler registering: bigdl.dllib.utils.common  Sample\n",
            "cls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.EvaluatedResult\n",
            "BigDLBasePickler registering: bigdl.dllib.utils.common  EvaluatedResult\n",
            "cls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.JTensor\n",
            "BigDLBasePickler registering: bigdl.dllib.utils.common  JTensor\n",
            "Successfully got a SparkContextcls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.JActivity\n",
            "BigDLBasePickler registering: bigdl.dllib.utils.common  JActivity\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VyfhD6HVQpm"
      },
      "source": [
        "This is the only place where you need to specify local or distributed mode. View [Orca Context](https://bigdl.readthedocs.io/en/latest/doc/Orca/Overview/orca-context.html) for more details.\n",
        "\n",
        "**Note**: You should export HADOOP_CONF_DIR=/path/to/hadoop/conf/dir when you run on Hadoop YARN cluster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld-pV8e-Vb7D"
      },
      "source": [
        "### **Step 2: Define the Model**\n",
        "\n",
        "You can then define the Keras model in the *Creator Function* using the standard TensroFlow 2 APIs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC1P7_gP9FKm"
      },
      "source": [
        "def model_creator(config):\n",
        "    import tensorflow as tf\n",
        "    model = tf.keras.Sequential(\n",
        "        [tf.keras.layers.Conv2D(20, kernel_size=(5, 5), strides=(1, 1), activation='tanh',\n",
        "                                input_shape=(28, 28, 1), padding='valid'),\n",
        "         tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
        "         tf.keras.layers.Conv2D(50, kernel_size=(5, 5), strides=(1, 1), activation='tanh',\n",
        "                                padding='valid'),\n",
        "         tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
        "         tf.keras.layers.Flatten(),\n",
        "         tf.keras.layers.Dense(500, activation='tanh'),\n",
        "         tf.keras.layers.Dense(10, activation='softmax'),\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiTnHATGYn_f"
      },
      "source": [
        "### **Step 3: Define Train Dataset**\n",
        "\n",
        "You can define the dataset in the _Creator Function_ using standard [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) APIs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YHW93myYykE"
      },
      "source": [
        "def preprocess(x, y):\n",
        "    import tensorflow as tf\n",
        "    x = tf.cast(tf.reshape(x, (28, 28, 1)), dtype=tf.float32) / 255.0\n",
        "    return x, y\n",
        "\n",
        "def train_data_creator(config, batch_size):\n",
        "    import tensorflow as tf\n",
        "    (train_feature, train_label), _ = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((train_feature, train_label))\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.map(preprocess)\n",
        "    dataset = dataset.shuffle(1000)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "def val_data_creator(config, batch_size):\n",
        "    import tensorflow as tf\n",
        "    _, (val_feature, val_label) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((val_feature, val_label))\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.map(preprocess)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnbOmWHsXOmg"
      },
      "source": [
        "### **Step 4: Fit with Orca Estimator**\n",
        "\n",
        "First, create an Estimator.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsNbQROFXNgU",
        "outputId": "b930b874-5ef9-4981-ad65-2f948c43f047",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from bigdl.orca.learn.tf2 import Estimator\n",
        "\n",
        "batch_size = 320\n",
        "est = Estimator.from_keras(model_creator=model_creator, workers_per_node=1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-18 01:02:29,957\tINFO services.py:1340 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://172.28.0.2:8265\u001b[39m\u001b[22m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'node_ip_address': '172.28.0.2', 'raylet_ip_address': '172.28.0.2', 'redis_address': '172.28.0.2:6379', 'object_store_address': '/tmp/ray/session_2022-03-18_01-02-24_788139_60/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-03-18_01-02-24_788139_60/sockets/raylet', 'webui_url': '172.28.0.2:8265', 'session_dir': '/tmp/ray/session_2022-03-18_01-02-24_788139_60', 'metrics_export_port': 56504, 'node_id': '41883e72914e55b98ce1353c46e363af447319ac086839717b3569d0'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bigdl/orca/learn/tf2/tf_runner.py:317: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m use distribute.MultiWorkerMirroredStrategy instead\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m 2022-03-18 01:02:44.592280: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bNtls5WXnzU"
      },
      "source": [
        "Next, fit the Estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imhbbDNXXsXR",
        "outputId": "5ea84ff9-e265-4ad3-ac04-4f5bd66235c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "max_epoch=1\n",
        "stats = est.fit(train_data_creator,\n",
        "                epochs=max_epoch,\n",
        "                batch_size=batch_size,\n",
        "                steps_per_epoch=60000 // batch_size,\n",
        "                validation_data=val_data_creator,\n",
        "                validation_steps=10000 // batch_size)\n",
        "est.save(\"/tmp/mnist_keras.ckpt\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "   16384/11490434 [..............................] - ETA: 0s\n",
            " 6995968/11490434 [=================>............] - ETA: 0s\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function preprocess at 0x7fbc54931050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m Cause: Unable to locate the source code of <function preprocess at 0x7fbc54931050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function preprocess at 0x7fbc549e4170> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m Cause: Unable to locate the source code of <function preprocess at 0x7fbc549e4170>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m 2022-03-18 01:02:47.559089: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m op: \"TensorSliceDataset\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m input: \"Placeholder/_0\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m input: \"Placeholder/_1\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   key: \"Toutput_types\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       type: DT_UINT8\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       type: DT_UINT8\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   key: \"_cardinality\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     i: 60000\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   key: \"is_files\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     b: false\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   key: \"metadata\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     s: \"\\n\\024TensorSliceDataset:0\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   key: \"output_shapes\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       shape {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m           size: 28\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m           size: 28\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       shape {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m experimental_type {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   type_id: TFT_PRODUCT\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     type_id: TFT_DATASET\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       type_id: TFT_PRODUCT\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         type_id: TFT_TENSOR\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m           type_id: TFT_UINT8\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         type_id: TFT_TENSOR\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m           type_id: TFT_UINT8\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     type_id: TFT_DATASET\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       type_id: TFT_PRODUCT\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         type_id: TFT_TENSOR\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m           type_id: TFT_UINT8\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         type_id: TFT_TENSOR\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m           type_id: TFT_UINT8\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m \n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m 2022-03-18 01:02:48.095865: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1/187 [..............................] - ETA: 8:35 - loss: 2.3401 - accuracy: 0.0906\n",
            "  2/187 [..............................] - ETA: 54s - loss: 2.3527 - accuracy: 0.1094 \n",
            "  3/187 [..............................] - ETA: 54s - loss: 2.1419 - accuracy: 0.2594\n",
            "  4/187 [..............................] - ETA: 55s - loss: 1.9656 - accuracy: 0.3609\n",
            "  5/187 [..............................] - ETA: 54s - loss: 1.8016 - accuracy: 0.4250\n",
            "  6/187 [..............................] - ETA: 54s - loss: 1.6454 - accuracy: 0.4891\n",
            "  7/187 [>.............................] - ETA: 53s - loss: 1.5204 - accuracy: 0.5344\n",
            "  8/187 [>.............................] - ETA: 53s - loss: 1.4050 - accuracy: 0.5750\n",
            "  9/187 [>.............................] - ETA: 53s - loss: 1.3068 - accuracy: 0.6108\n",
            " 10/187 [>.............................] - ETA: 52s - loss: 1.2304 - accuracy: 0.6350\n",
            " 11/187 [>.............................] - ETA: 52s - loss: 1.1696 - accuracy: 0.6517\n",
            " 12/187 [>.............................] - ETA: 52s - loss: 1.1116 - accuracy: 0.6672\n",
            " 13/187 [=>............................] - ETA: 51s - loss: 1.0640 - accuracy: 0.6793\n",
            " 14/187 [=>............................] - ETA: 51s - loss: 1.0289 - accuracy: 0.6906\n",
            " 15/187 [=>............................] - ETA: 51s - loss: 0.9925 - accuracy: 0.7015\n",
            " 16/187 [=>............................] - ETA: 50s - loss: 0.9605 - accuracy: 0.7105\n",
            " 17/187 [=>............................] - ETA: 50s - loss: 0.9271 - accuracy: 0.7219\n",
            " 18/187 [=>............................] - ETA: 50s - loss: 0.8920 - accuracy: 0.7333\n",
            " 19/187 [==>...........................] - ETA: 49s - loss: 0.8642 - accuracy: 0.7418\n",
            " 20/187 [==>...........................] - ETA: 49s - loss: 0.8388 - accuracy: 0.7494\n",
            " 21/187 [==>...........................] - ETA: 49s - loss: 0.8165 - accuracy: 0.7560\n",
            " 22/187 [==>...........................] - ETA: 48s - loss: 0.7970 - accuracy: 0.7618\n",
            " 23/187 [==>...........................] - ETA: 48s - loss: 0.7799 - accuracy: 0.7683\n",
            " 24/187 [==>...........................] - ETA: 48s - loss: 0.7617 - accuracy: 0.7742\n",
            " 25/187 [===>..........................] - ETA: 47s - loss: 0.7475 - accuracy: 0.7788\n",
            " 26/187 [===>..........................] - ETA: 47s - loss: 0.7335 - accuracy: 0.7835\n",
            " 27/187 [===>..........................] - ETA: 47s - loss: 0.7226 - accuracy: 0.7861\n",
            " 28/187 [===>..........................] - ETA: 46s - loss: 0.7101 - accuracy: 0.7897\n",
            " 29/187 [===>..........................] - ETA: 46s - loss: 0.6992 - accuracy: 0.7927\n",
            " 30/187 [===>..........................] - ETA: 46s - loss: 0.6892 - accuracy: 0.7955\n",
            " 31/187 [===>..........................] - ETA: 45s - loss: 0.6749 - accuracy: 0.8000\n",
            " 32/187 [====>.........................] - ETA: 45s - loss: 0.6609 - accuracy: 0.8045\n",
            " 33/187 [====>.........................] - ETA: 45s - loss: 0.6469 - accuracy: 0.8085\n",
            " 34/187 [====>.........................] - ETA: 45s - loss: 0.6367 - accuracy: 0.8112\n",
            " 35/187 [====>.........................] - ETA: 45s - loss: 0.6272 - accuracy: 0.8141\n",
            " 36/187 [====>.........................] - ETA: 44s - loss: 0.6169 - accuracy: 0.8173\n",
            " 37/187 [====>.........................] - ETA: 44s - loss: 0.6083 - accuracy: 0.8201\n",
            " 38/187 [=====>........................] - ETA: 43s - loss: 0.6021 - accuracy: 0.8221\n",
            " 39/187 [=====>........................] - ETA: 43s - loss: 0.5956 - accuracy: 0.8240\n",
            " 40/187 [=====>........................] - ETA: 43s - loss: 0.5897 - accuracy: 0.8259\n",
            " 41/187 [=====>........................] - ETA: 43s - loss: 0.5832 - accuracy: 0.8280\n",
            " 42/187 [=====>........................] - ETA: 42s - loss: 0.5768 - accuracy: 0.8292\n",
            " 43/187 [=====>........................] - ETA: 42s - loss: 0.5701 - accuracy: 0.8311\n",
            " 44/187 [======>.......................] - ETA: 42s - loss: 0.5640 - accuracy: 0.8327\n",
            " 45/187 [======>.......................] - ETA: 41s - loss: 0.5569 - accuracy: 0.8349\n",
            " 46/187 [======>.......................] - ETA: 41s - loss: 0.5500 - accuracy: 0.8374\n",
            " 47/187 [======>.......................] - ETA: 41s - loss: 0.5430 - accuracy: 0.8395\n",
            " 48/187 [======>.......................] - ETA: 40s - loss: 0.5364 - accuracy: 0.8415\n",
            " 49/187 [======>.......................] - ETA: 40s - loss: 0.5304 - accuracy: 0.8435\n",
            " 50/187 [=======>......................] - ETA: 40s - loss: 0.5239 - accuracy: 0.8454\n",
            " 51/187 [=======>......................] - ETA: 39s - loss: 0.5178 - accuracy: 0.8471\n",
            " 52/187 [=======>......................] - ETA: 39s - loss: 0.5133 - accuracy: 0.8485\n",
            " 53/187 [=======>......................] - ETA: 39s - loss: 0.5081 - accuracy: 0.8499\n",
            " 54/187 [=======>......................] - ETA: 39s - loss: 0.5025 - accuracy: 0.8517\n",
            " 55/187 [=======>......................] - ETA: 38s - loss: 0.4976 - accuracy: 0.8533\n",
            " 56/187 [=======>......................] - ETA: 38s - loss: 0.4926 - accuracy: 0.8548\n",
            " 57/187 [========>.....................] - ETA: 38s - loss: 0.4869 - accuracy: 0.8565\n",
            " 58/187 [========>.....................] - ETA: 37s - loss: 0.4827 - accuracy: 0.8575\n",
            " 59/187 [========>.....................] - ETA: 37s - loss: 0.4781 - accuracy: 0.8588\n",
            " 60/187 [========>.....................] - ETA: 37s - loss: 0.4729 - accuracy: 0.8603\n",
            " 61/187 [========>.....................] - ETA: 37s - loss: 0.4678 - accuracy: 0.8617\n",
            " 62/187 [========>.....................] - ETA: 36s - loss: 0.4626 - accuracy: 0.8634\n",
            " 63/187 [=========>....................] - ETA: 36s - loss: 0.4602 - accuracy: 0.8642\n",
            " 64/187 [=========>....................] - ETA: 36s - loss: 0.4553 - accuracy: 0.8657\n",
            " 65/187 [=========>....................] - ETA: 35s - loss: 0.4508 - accuracy: 0.8670\n",
            " 66/187 [=========>....................] - ETA: 35s - loss: 0.4469 - accuracy: 0.8681\n",
            " 67/187 [=========>....................] - ETA: 35s - loss: 0.4429 - accuracy: 0.8694\n",
            " 68/187 [=========>....................] - ETA: 34s - loss: 0.4395 - accuracy: 0.8706\n",
            " 69/187 [==========>...................] - ETA: 34s - loss: 0.4355 - accuracy: 0.8719\n",
            " 70/187 [==========>...................] - ETA: 34s - loss: 0.4311 - accuracy: 0.8731\n",
            " 71/187 [==========>...................] - ETA: 34s - loss: 0.4268 - accuracy: 0.8745\n",
            " 72/187 [==========>...................] - ETA: 33s - loss: 0.4232 - accuracy: 0.8756\n",
            " 73/187 [==========>...................] - ETA: 33s - loss: 0.4195 - accuracy: 0.8768\n",
            " 74/187 [==========>...................] - ETA: 33s - loss: 0.4156 - accuracy: 0.8777\n",
            " 75/187 [===========>..................] - ETA: 32s - loss: 0.4124 - accuracy: 0.8787\n",
            " 76/187 [===========>..................] - ETA: 32s - loss: 0.4088 - accuracy: 0.8796\n",
            " 77/187 [===========>..................] - ETA: 32s - loss: 0.4057 - accuracy: 0.8805\n",
            " 78/187 [===========>..................] - ETA: 31s - loss: 0.4036 - accuracy: 0.8810\n",
            " 79/187 [===========>..................] - ETA: 31s - loss: 0.4009 - accuracy: 0.8818\n",
            " 80/187 [===========>..................] - ETA: 31s - loss: 0.3988 - accuracy: 0.8824\n",
            " 81/187 [===========>..................] - ETA: 31s - loss: 0.3956 - accuracy: 0.8833\n",
            " 82/187 [============>.................] - ETA: 30s - loss: 0.3933 - accuracy: 0.8839\n",
            " 83/187 [============>.................] - ETA: 30s - loss: 0.3918 - accuracy: 0.8844\n",
            " 84/187 [============>.................] - ETA: 30s - loss: 0.3896 - accuracy: 0.8849\n",
            " 85/187 [============>.................] - ETA: 29s - loss: 0.3866 - accuracy: 0.8857\n",
            " 86/187 [============>.................] - ETA: 29s - loss: 0.3835 - accuracy: 0.8866\n",
            " 87/187 [============>.................] - ETA: 29s - loss: 0.3817 - accuracy: 0.8869\n",
            " 88/187 [=============>................] - ETA: 29s - loss: 0.3785 - accuracy: 0.8879\n",
            " 89/187 [=============>................] - ETA: 28s - loss: 0.3753 - accuracy: 0.8888\n",
            " 90/187 [=============>................] - ETA: 28s - loss: 0.3723 - accuracy: 0.8897\n",
            " 91/187 [=============>................] - ETA: 28s - loss: 0.3697 - accuracy: 0.8904\n",
            " 92/187 [=============>................] - ETA: 27s - loss: 0.3673 - accuracy: 0.8912\n",
            " 93/187 [=============>................] - ETA: 27s - loss: 0.3646 - accuracy: 0.8920\n",
            " 94/187 [==============>...............] - ETA: 27s - loss: 0.3621 - accuracy: 0.8928\n",
            " 95/187 [==============>...............] - ETA: 27s - loss: 0.3603 - accuracy: 0.8933\n",
            " 96/187 [==============>...............] - ETA: 26s - loss: 0.3587 - accuracy: 0.8939\n",
            " 97/187 [==============>...............] - ETA: 26s - loss: 0.3571 - accuracy: 0.8943\n",
            " 98/187 [==============>...............] - ETA: 26s - loss: 0.3550 - accuracy: 0.8949\n",
            " 99/187 [==============>...............] - ETA: 25s - loss: 0.3526 - accuracy: 0.8957\n",
            "100/187 [===============>..............] - ETA: 25s - loss: 0.3505 - accuracy: 0.8963\n",
            "101/187 [===============>..............] - ETA: 25s - loss: 0.3487 - accuracy: 0.8968\n",
            "102/187 [===============>..............] - ETA: 24s - loss: 0.3465 - accuracy: 0.8973\n",
            "103/187 [===============>..............] - ETA: 24s - loss: 0.3445 - accuracy: 0.8980\n",
            "104/187 [===============>..............] - ETA: 24s - loss: 0.3421 - accuracy: 0.8987\n",
            "105/187 [===============>..............] - ETA: 24s - loss: 0.3401 - accuracy: 0.8992\n",
            "106/187 [================>.............] - ETA: 23s - loss: 0.3381 - accuracy: 0.8998\n",
            "107/187 [================>.............] - ETA: 23s - loss: 0.3361 - accuracy: 0.9003\n",
            "108/187 [================>.............] - ETA: 23s - loss: 0.3336 - accuracy: 0.9011\n",
            "109/187 [================>.............] - ETA: 22s - loss: 0.3316 - accuracy: 0.9017\n",
            "110/187 [================>.............] - ETA: 22s - loss: 0.3296 - accuracy: 0.9023\n",
            "111/187 [================>.............] - ETA: 22s - loss: 0.3280 - accuracy: 0.9028\n",
            "112/187 [================>.............] - ETA: 22s - loss: 0.3262 - accuracy: 0.9033\n",
            "113/187 [=================>............] - ETA: 21s - loss: 0.3246 - accuracy: 0.9036\n",
            "114/187 [=================>............] - ETA: 21s - loss: 0.3229 - accuracy: 0.9041\n",
            "115/187 [=================>............] - ETA: 21s - loss: 0.3212 - accuracy: 0.9046\n",
            "116/187 [=================>............] - ETA: 20s - loss: 0.3199 - accuracy: 0.9050\n",
            "117/187 [=================>............] - ETA: 20s - loss: 0.3182 - accuracy: 0.9055\n",
            "118/187 [=================>............] - ETA: 20s - loss: 0.3164 - accuracy: 0.9060\n",
            "119/187 [==================>...........] - ETA: 19s - loss: 0.3145 - accuracy: 0.9065\n",
            "120/187 [==================>...........] - ETA: 19s - loss: 0.3127 - accuracy: 0.9071\n",
            "121/187 [==================>...........] - ETA: 19s - loss: 0.3112 - accuracy: 0.9075\n",
            "122/187 [==================>...........] - ETA: 19s - loss: 0.3097 - accuracy: 0.9078\n",
            "123/187 [==================>...........] - ETA: 18s - loss: 0.3079 - accuracy: 0.9084\n",
            "124/187 [==================>...........] - ETA: 18s - loss: 0.3064 - accuracy: 0.9089\n",
            "125/187 [===================>..........] - ETA: 18s - loss: 0.3046 - accuracy: 0.9095\n",
            "126/187 [===================>..........] - ETA: 17s - loss: 0.3030 - accuracy: 0.9100\n",
            "127/187 [===================>..........] - ETA: 17s - loss: 0.3019 - accuracy: 0.9103\n",
            "128/187 [===================>..........] - ETA: 17s - loss: 0.3006 - accuracy: 0.9107\n",
            "129/187 [===================>..........] - ETA: 16s - loss: 0.2990 - accuracy: 0.9112\n",
            "130/187 [===================>..........] - ETA: 16s - loss: 0.2977 - accuracy: 0.9115\n",
            "131/187 [====================>.........] - ETA: 16s - loss: 0.2960 - accuracy: 0.9120\n",
            "132/187 [====================>.........] - ETA: 16s - loss: 0.2945 - accuracy: 0.9124\n",
            "133/187 [====================>.........] - ETA: 15s - loss: 0.2931 - accuracy: 0.9128\n",
            "134/187 [====================>.........] - ETA: 15s - loss: 0.2920 - accuracy: 0.9131\n",
            "135/187 [====================>.........] - ETA: 15s - loss: 0.2910 - accuracy: 0.9133\n",
            "136/187 [====================>.........] - ETA: 14s - loss: 0.2896 - accuracy: 0.9137\n",
            "137/187 [====================>.........] - ETA: 14s - loss: 0.2883 - accuracy: 0.9141\n",
            "138/187 [=====================>........] - ETA: 14s - loss: 0.2870 - accuracy: 0.9145\n",
            "139/187 [=====================>........] - ETA: 14s - loss: 0.2856 - accuracy: 0.9149\n",
            "140/187 [=====================>........] - ETA: 13s - loss: 0.2845 - accuracy: 0.9152\n",
            "141/187 [=====================>........] - ETA: 13s - loss: 0.2834 - accuracy: 0.9154\n",
            "142/187 [=====================>........] - ETA: 13s - loss: 0.2825 - accuracy: 0.9156\n",
            "143/187 [=====================>........] - ETA: 12s - loss: 0.2822 - accuracy: 0.9157\n",
            "144/187 [======================>.......] - ETA: 12s - loss: 0.2809 - accuracy: 0.9160\n",
            "145/187 [======================>.......] - ETA: 12s - loss: 0.2794 - accuracy: 0.9164\n",
            "146/187 [======================>.......] - ETA: 12s - loss: 0.2785 - accuracy: 0.9168\n",
            "147/187 [======================>.......] - ETA: 11s - loss: 0.2779 - accuracy: 0.9170\n",
            "148/187 [======================>.......] - ETA: 11s - loss: 0.2769 - accuracy: 0.9173\n",
            "149/187 [======================>.......] - ETA: 11s - loss: 0.2755 - accuracy: 0.9177\n",
            "150/187 [=======================>......] - ETA: 10s - loss: 0.2742 - accuracy: 0.9181\n",
            "151/187 [=======================>......] - ETA: 10s - loss: 0.2729 - accuracy: 0.9184\n",
            "152/187 [=======================>......] - ETA: 10s - loss: 0.2714 - accuracy: 0.9189\n",
            "153/187 [=======================>......] - ETA: 9s - loss: 0.2703 - accuracy: 0.9191 \n",
            "154/187 [=======================>......] - ETA: 9s - loss: 0.2692 - accuracy: 0.9194\n",
            "155/187 [=======================>......] - ETA: 9s - loss: 0.2683 - accuracy: 0.9197\n",
            "156/187 [========================>.....] - ETA: 9s - loss: 0.2674 - accuracy: 0.9199\n",
            "157/187 [========================>.....] - ETA: 8s - loss: 0.2664 - accuracy: 0.9202\n",
            "158/187 [========================>.....] - ETA: 8s - loss: 0.2651 - accuracy: 0.9205\n",
            "159/187 [========================>.....] - ETA: 8s - loss: 0.2641 - accuracy: 0.9209\n",
            "160/187 [========================>.....] - ETA: 7s - loss: 0.2629 - accuracy: 0.9212\n",
            "161/187 [========================>.....] - ETA: 7s - loss: 0.2620 - accuracy: 0.9215\n",
            "162/187 [========================>.....] - ETA: 7s - loss: 0.2607 - accuracy: 0.9219\n",
            "163/187 [=========================>....] - ETA: 7s - loss: 0.2596 - accuracy: 0.9222\n",
            "164/187 [=========================>....] - ETA: 6s - loss: 0.2585 - accuracy: 0.9225\n",
            "165/187 [=========================>....] - ETA: 6s - loss: 0.2582 - accuracy: 0.9226\n",
            "166/187 [=========================>....] - ETA: 6s - loss: 0.2575 - accuracy: 0.9228\n",
            "167/187 [=========================>....] - ETA: 5s - loss: 0.2566 - accuracy: 0.9231\n",
            "168/187 [=========================>....] - ETA: 5s - loss: 0.2556 - accuracy: 0.9234\n",
            "169/187 [==========================>...] - ETA: 5s - loss: 0.2544 - accuracy: 0.9238\n",
            "170/187 [==========================>...] - ETA: 4s - loss: 0.2534 - accuracy: 0.9242\n",
            "171/187 [==========================>...] - ETA: 4s - loss: 0.2525 - accuracy: 0.9245\n",
            "172/187 [==========================>...] - ETA: 4s - loss: 0.2514 - accuracy: 0.9248\n",
            "173/187 [==========================>...] - ETA: 4s - loss: 0.2505 - accuracy: 0.9251\n",
            "174/187 [==========================>...] - ETA: 3s - loss: 0.2497 - accuracy: 0.9254\n",
            "175/187 [===========================>..] - ETA: 3s - loss: 0.2493 - accuracy: 0.9255\n",
            "176/187 [===========================>..] - ETA: 3s - loss: 0.2484 - accuracy: 0.9258\n",
            "177/187 [===========================>..] - ETA: 2s - loss: 0.2471 - accuracy: 0.9262\n",
            "178/187 [===========================>..] - ETA: 2s - loss: 0.2462 - accuracy: 0.9264\n",
            "179/187 [===========================>..] - ETA: 2s - loss: 0.2453 - accuracy: 0.9267\n",
            "180/187 [===========================>..] - ETA: 2s - loss: 0.2443 - accuracy: 0.9270\n",
            "181/187 [============================>.] - ETA: 1s - loss: 0.2432 - accuracy: 0.9273\n",
            "182/187 [============================>.] - ETA: 1s - loss: 0.2420 - accuracy: 0.9276\n",
            "183/187 [============================>.] - ETA: 1s - loss: 0.2411 - accuracy: 0.9279\n",
            "184/187 [============================>.] - ETA: 0s - loss: 0.2402 - accuracy: 0.9282\n",
            "185/187 [============================>.] - ETA: 0s - loss: 0.2396 - accuracy: 0.9285\n",
            "186/187 [============================>.] - ETA: 0s - loss: 0.2389 - accuracy: 0.9287\n",
            "187/187 [==============================] - ETA: 0s - loss: 0.2381 - accuracy: 0.9290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m 2022-03-18 01:03:45.633685: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m op: \"TensorSliceDataset\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m input: \"Placeholder/_0\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m input: \"Placeholder/_1\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   key: \"Toutput_types\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       type: DT_UINT8\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       type: DT_UINT8\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   key: \"_cardinality\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     i: 10000\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   key: \"is_files\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     b: false\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   key: \"metadata\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     s: \"\\n\\024TensorSliceDataset:5\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   key: \"output_shapes\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       shape {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m           size: 28\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m           size: 28\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       shape {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m experimental_type {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   type_id: TFT_PRODUCT\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     type_id: TFT_DATASET\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       type_id: TFT_PRODUCT\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         type_id: TFT_TENSOR\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m           type_id: TFT_UINT8\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         type_id: TFT_TENSOR\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m           type_id: TFT_UINT8\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     type_id: TFT_DATASET\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       type_id: TFT_PRODUCT\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         type_id: TFT_TENSOR\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m           type_id: TFT_UINT8\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         type_id: TFT_TENSOR\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m           type_id: TFT_UINT8\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m \n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m 2022-03-18 01:03:45.703870: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r187/187 [==============================] - 60s 308ms/step - loss: 0.2381 - accuracy: 0.9290 - val_loss: 0.0832 - val_accuracy: 0.9721\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/tmp/mnist_keras.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRdASNtRAbiN"
      },
      "source": [
        "Finally, evaluate using the Estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDNoiHiquX0A",
        "outputId": "7c22fb41-1012-47f6-ff35-8b19eefc3652",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "stats = est.evaluate(val_data_creator, num_steps=10000 // batch_size)\n",
        "est.shutdown()\n",
        "print(stats)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function preprocess at 0x7fbc51b3fc20> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m Cause: Unable to locate the source code of <function preprocess at 0x7fbc51b3fc20>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m 2022-03-18 01:04:12.435779: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m op: \"TensorSliceDataset\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m input: \"Placeholder/_0\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m input: \"Placeholder/_1\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   key: \"Toutput_types\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       type: DT_UINT8\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       type: DT_UINT8\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   key: \"_cardinality\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     i: 10000\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   key: \"is_files\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     b: false\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   key: \"metadata\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     s: \"\\n\\025TensorSliceDataset:35\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   key: \"output_shapes\"\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       shape {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m           size: 28\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m           size: 28\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       shape {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m experimental_type {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   type_id: TFT_PRODUCT\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     type_id: TFT_DATASET\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       type_id: TFT_PRODUCT\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         type_id: TFT_TENSOR\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m           type_id: TFT_UINT8\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         type_id: TFT_TENSOR\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m           type_id: TFT_UINT8\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     type_id: TFT_DATASET\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       type_id: TFT_PRODUCT\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         type_id: TFT_TENSOR\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m           type_id: TFT_UINT8\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         type_id: TFT_TENSOR\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         args {\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m           type_id: TFT_UINT8\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=603)\u001b[0m \r 1/31 [..............................] - ETA: 3s - loss: 0.0265 - accuracy: 1.0000\n",
            "10/31 [========>.....................] - ETA: 0s - loss: 0.0580 - accuracy: 0.9844\n",
            "20/31 [==================>...........] - ETA: 0s - loss: 0.0903 - accuracy: 0.9703\n",
            "28/31 [==========================>...] - ETA: 0s - loss: 0.0943 - accuracy: 0.9676\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0982 - accuracy: 0.9667\n",
            "{'validation_loss': 0.09824127703905106, 'validation_accuracy': 0.9667338728904724}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyRtP6lqieej"
      },
      "source": [
        "Now, the accuracy of this model has reached 98%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC4KhlHxXakk",
        "outputId": "62ec4f5d-0353-48c2-b5e9-5562ee128275",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Stop orca context when your program finishes\n",
        "stop_orca_context()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopping orca context\n"
          ]
        }
      ]
    }
  ]
}